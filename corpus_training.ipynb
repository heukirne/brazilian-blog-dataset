{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "# load corpus\n",
    "corpus_feat = pd.read_csv('corpus_liwc_mtx.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['diario' 'outro']\n",
      "0    1\n",
      "1   -1\n",
      "Name: class_, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# fix labels to binary\n",
    "def classFit(x):\n",
    "    if x['class'] == \"diario\":\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "corpus_feat['class_'] = corpus_feat.apply(classFit,axis=1)\n",
    "target = corpus_feat['class_'].values\n",
    "\n",
    "print(corpus_feat['class'].values[:2])\n",
    "print(corpus_feat['class_'][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_feat.drop('Unnamed: 0', axis=1,inplace=True)\n",
    "corpus_feat.drop('confidence', axis=1,inplace=True)\n",
    "corpus_feat.drop('class', axis=1,inplace=True)\n",
    "#corpus_feat = corpus_feat[corpus_feat.wc.apply(lambda x: str(x).isnumeric())]\n",
    "wc_vector = corpus_feat['wc']\n",
    "corpus_feat.drop('wc', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(534, 64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate features matrix\n",
    "data = corpus_feat.drop('class_', 1).values\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[CV] C=1 .............................................................\n",
      "[CV] C=1 .............................................................\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .............................. C=1, score=0.648045, total=   0.0s\n",
      "[CV] .............................. C=1, score=0.646067, total=   0.0s\n",
      "[CV] C=10 ............................................................\n",
      "[CV] C=10 ............................................................\n",
      "[CV] .............................. C=1, score=0.649718, total=   0.0s\n",
      "[CV] C=10 ............................................................\n",
      "[CV] ............................. C=10, score=0.648045, total=   0.1s\n",
      "[CV] ............................. C=10, score=0.649718, total=   0.1s\n",
      "[CV] ............................. C=10, score=0.646067, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   4 out of   6 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=3)]: Done   6 out of   6 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=3, param_grid={'C': [1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'C':[1, 10]}\n",
    "grid_search = GridSearchCV(SVC(kernel='rbf'), parameters, cv=3, n_jobs=3, verbose=3, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.647940074906\n",
      "{'C': 1}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.647960006451\n",
      "0.647960006451\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "model = SVC(kernel='rbf',C=1,gamma=0.1)\n",
    "\n",
    "precision = cross_val_score(model, data, target, cv=10, scoring='precision').mean()\n",
    "acc = cross_val_score(model, data, target, cv=10, scoring='accuracy').mean()\n",
    "recall = cross_val_score(model, data, target, cv=10, scoring='recall').mean()\n",
    "print(precision)\n",
    "print(acc)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.740516135105\n",
      "0.670680804171\n",
      "0.761008403361\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(C=1)\n",
    "\n",
    "precision = cross_val_score(model, data, target, cv=10, scoring='precision').mean()\n",
    "acc = cross_val_score(model, data, target, cv=10, scoring='accuracy').mean()\n",
    "recall = cross_val_score(model, data, target, cv=10, scoring='recall').mean()\n",
    "print(precision)\n",
    "print(acc)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Naive Bayses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.699760764395\n",
      "0.638488415847\n",
      "0.774285714286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "\n",
    "precision = cross_val_score(model, data, target, cv=10, scoring='precision').mean()\n",
    "acc = cross_val_score(model, data, target, cv=10, scoring='accuracy').mean()\n",
    "recall = cross_val_score(model, data, target, cv=10, scoring='recall').mean()\n",
    "print(precision)\n",
    "print(acc)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.818782558502\n",
      "0.741650540235\n",
      "0.774201680672\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB()\n",
    "\n",
    "precision = cross_val_score(model, data, target, cv=10, scoring='precision').mean()\n",
    "acc = cross_val_score(model, data, target, cv=10, scoring='accuracy').mean()\n",
    "recall = cross_val_score(model, data, target, cv=10, scoring='recall').mean()\n",
    "print(precision)\n",
    "print(acc)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outro -7.9130506381 filler\n",
      "outro -7.48738282267 death\n",
      "outro -7.26423927136 assent\n",
      "outro -6.89959615777 family\n",
      "outro -6.80092463026 we\n",
      "outro -6.68388758494 anx\n",
      "outro -6.52675627698 home\n",
      "outro -6.50780435156 relig\n",
      "outro -6.49784162906 future\n",
      "outro -6.28141201568 friend\n",
      "outro -6.26458826411 anger\n",
      "outro -6.02335611301 health\n",
      "outro -6.0156755837 sad\n",
      "outro -5.76045821478 hear\n",
      "outro -5.69229556335 sexual\n",
      "\n",
      "diario -2.15661440035 funct\n",
      "diario -2.38244796028 cogmech\n",
      "diario -2.94462009681 relativ\n",
      "diario -3.10032718798 social\n",
      "diario -3.14483360076 pronoun\n",
      "diario -3.34594265292 verb\n",
      "diario -3.38490476055 incl\n",
      "diario -3.41659124489 preps\n",
      "diario -3.54224746579 ipron\n",
      "diario -3.62301063072 ppron\n",
      "diario -3.75011010854 space\n",
      "diario -3.75792140284 conj\n",
      "diario -3.76845924721 tentat\n",
      "diario -3.91325973919 affect\n",
      "diario -3.94401095223 time\n"
     ]
    }
   ],
   "source": [
    "model.fit(data,target)\n",
    "n = 15 \n",
    "\n",
    "class_labels = ['outro','diario']\n",
    "feature_names = ['funct','pronoun','ppron','i','we','you','shehe','they','ipron','article','verb','auxverb','past','present','future','adverb','preps','conj','negate','quant','number','swear','social','family','friend','humans','affect','posemo','negemo','anx','anger','sad','cogmech','insight','cause','discrep','tentat','certain','inhib','incl','excl','percept','see','hear','feel','bio','body','health','sexual','ingest','relativ','motion','space','time','work','achieve','leisure','home','money','relig','death','assent','nonfl','filler']\n",
    "topn_class1 = sorted(zip(model.coef_[0], feature_names))[:n]\n",
    "topn_class2 = sorted(zip(model.coef_[0], feature_names))[-n:]\n",
    "\n",
    "for coef, feat in topn_class1:\n",
    "    print (class_labels[0], coef, feat)\n",
    "\n",
    "print()\n",
    "\n",
    "for coef, feat in reversed(topn_class2):\n",
    "    print (class_labels[1], coef, feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### confidence-weighted linear classifier (Dredze et al., 2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: acc(0.651685393258), prec(0.652326615077), rec(0.988023952096)\n",
      "AP: acc(0.666666666667), prec(0.742554564025), rec(0.831800086977)\n",
      "PA: acc(0.64606741573), prec(0.647236067697), rec(0.997005988024)\n",
      "PA1: acc(0.64606741573), prec(0.647236067697), rec(0.997005988024)\n",
      "PA2: acc(0.64606741573), prec(0.647236067697), rec(0.997005988024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAK: acc(0.352059925094), prec(0.0), rec(0.0)\n",
      "CW: acc(0.662921348315), prec(0.695310412399), rec(0.852122570501)\n",
      "AL: acc(0.647940074906), prec(0.649877807181), rec(0.988023952096)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import oll\n",
    "import numpy as np\n",
    "\n",
    "## manual 10-fold cross-validation\n",
    "kf = KFold(n_splits=2, random_state=None, shuffle=False)\n",
    "\n",
    "methods = [\"P\" ,\"AP\" ,\"PA\" ,\"PA1\",\"PA2\" ,\"PAK\",\"CW\" ,\"AL\"]\n",
    "\n",
    "for m in methods:\n",
    "\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(data):\n",
    "        model = oll.oll(m, C=1)\n",
    "        \n",
    "        X_train, X_test = data[train_index], data[test_index]\n",
    "        y_train, y_test = target[train_index], target[test_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        predicted = model.predict(X_test)\n",
    "\n",
    "        accuracy.append(accuracy_score(y_test, predicted))\n",
    "        precision.append(precision_score(y_test, predicted))\n",
    "        recall.append(recall_score(y_test, predicted))\n",
    "\n",
    "    print(m + ': acc(' + str(np.mean(accuracy)) \n",
    "          + '), prec(' + str(np.mean(precision))\n",
    "          + '), rec(' + str(np.mean(recall)) + ')'\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
