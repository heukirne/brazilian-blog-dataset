{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import oll\n",
    "\n",
    "corpus = pd.read_csv('corpus.csv.gz', compression='gzip')\n",
    "stopwords = stopwords.words(\"portuguese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(551, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#corpus = corpus[corpus['_golden'] == False]\n",
    "corpus = corpus[corpus['qual_a_melhor_classificao_para_esse_texto:confidence'] == 1]\n",
    "corpus = corpus.reset_index()\n",
    "corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['diario' 'diario']\n",
      "0    1\n",
      "1    1\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# fix labels to binary\n",
    "def classFit(x):\n",
    "    if x['qual_a_melhor_classificao_para_esse_texto'] == \"diario\":\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "corpus['class'] = corpus.apply(classFit,axis=1)\n",
    "target = corpus['class'].values\n",
    "\n",
    "print(corpus['qual_a_melhor_classificao_para_esse_texto'].values[:2])\n",
    "print(corpus['class'][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.stem\n",
    "portuguese_stemmer = nltk.stem.RSLPStemmer()\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(TfidfVectorizer,self).build_analyzer()\n",
    "        return lambda doc: (portuguese_stemmer.stem(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500: acc(0.773162055336), prec(0.787614678899), rec(0.89360743365)\n",
      "600: acc(0.77314229249), prec(0.782922654913), rec(0.901671949779)\n",
      "700: acc(0.774953886693), prec(0.776339147029), rec(0.918810988874)\n",
      "800: acc(0.782233201581), prec(0.780231023102), rec(0.927279507738)\n",
      "900: acc(0.79312911726), prec(0.788461538462), rec(0.933261855926)\n",
      "1000: acc(0.78222002635), prec(0.778484043711), rec(0.930169681149)\n",
      "1100: acc(0.78220685112), prec(0.778299011711), rec(0.929967679781)\n",
      "1200: acc(0.782213438735), prec(0.775792464115), rec(0.935748026602)\n",
      "1300: acc(0.778563899868), prec(0.774526919264), rec(0.929967679781)\n",
      "1400: acc(0.77674571805), prec(0.770164348925), rec(0.935344023867)\n",
      "1500: acc(0.771297760211), prec(0.76364628821), rec(0.93803219591)\n",
      "1600: acc(0.778557312253), prec(0.767070484581), rec(0.946702716141)\n",
      "1700: acc(0.782173913043), prec(0.770436303766), rec(0.946500714774)\n",
      "1800: acc(0.785816864295), prec(0.770419916744), rec(0.955171235005)\n",
      "1900: acc(0.782180500659), prec(0.768126338762), rec(0.952281061595)\n",
      "2000: acc(0.789453227931), prec(0.773902757383), rec(0.955171235005)\n",
      "2100: acc(0.782180500659), prec(0.767000400481), rec(0.955171235005)\n",
      "2200: acc(0.780362318841), prec(0.765159219158), rec(0.954969233638)\n",
      "2300: acc(0.78581027668), prec(0.768040009526), rec(0.960749580459)\n",
      "2400: acc(0.787628458498), prec(0.769736842105), rec(0.960749580459)\n",
      "2500: acc(0.787628458498), prec(0.769736842105), rec(0.960749580459)\n",
      "2600: acc(0.785816864295), prec(0.768013100437), rec(0.960749580459)\n",
      "2700: acc(0.787628458498), prec(0.768610715979), rec(0.963639753869)\n",
      "2800: acc(0.783998682477), prec(0.765210409854), rec(0.963639753869)\n",
      "2900: acc(0.783998682477), prec(0.765210409854), rec(0.963639753869)\n",
      "3000: acc(0.780368906456), prec(0.762925969448), rec(0.960749580459)\n",
      "3100: acc(0.782180500659), prec(0.764634722058), rec(0.960749580459)\n",
      "3200: acc(0.783998682477), prec(0.765210409854), rec(0.963639753869)\n",
      "3300: acc(0.78582345191), prec(0.766983321533), rec(0.963841755236)\n",
      "3400: acc(0.784005270092), prec(0.766417733523), rec(0.960951581826)\n",
      "3500: acc(0.780375494071), prec(0.76302700374), rec(0.960951581826)\n",
      "3600: acc(0.782187088274), prec(0.764741169066), rec(0.960951581826)\n",
      "3700: acc(0.780375494071), prec(0.76302700374), rec(0.960951581826)\n",
      "3800: acc(0.782193675889), prec(0.764703568197), rec(0.960951581826)\n",
      "3900: acc(0.782193675889), prec(0.764703568197), rec(0.960951581826)\n",
      "4000: acc(0.782193675889), prec(0.764703568197), rec(0.960951581826)\n",
      "4100: acc(0.782193675889), prec(0.764703568197), rec(0.960951581826)\n",
      "4200: acc(0.784011857708), prec(0.765269156207), rec(0.963841755236)\n",
      "4300: acc(0.782193675889), prec(0.764703568197), rec(0.960951581826)\n",
      "4400: acc(0.780375494071), prec(0.764132861744), rec(0.958061408416)\n",
      "4500: acc(0.784005270092), prec(0.766417733523), rec(0.960951581826)\n",
      "4600: acc(0.780375494071), prec(0.76302700374), rec(0.960951581826)\n",
      "4700: acc(0.778557312253), prec(0.762451315945), rec(0.958061408416)\n",
      "4800: acc(0.782193675889), prec(0.763597551466), rec(0.963841755236)\n",
      "4900: acc(0.780375494071), prec(0.761940805434), rec(0.963841755236)\n"
     ]
    }
   ],
   "source": [
    "## manual 10-fold cross-validation\n",
    "kf = KFold(n_splits=2, random_state=None, shuffle=False)\n",
    "\n",
    "for i in range(500,5000,100):\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    \n",
    "    data = TfidfVectorizer(max_features=i, strip_accents='unicode', stop_words=stopwords).fit_transform(corpus.content)\n",
    "\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        model = oll.oll(\"CW\", C=1)\n",
    "        \n",
    "        X_train, X_test = data[train_index], data[test_index]\n",
    "        y_train, y_test = target[train_index], target[test_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        predicted = model.predict(X_test)\n",
    "\n",
    "        accuracy.append(accuracy_score(y_test, predicted))\n",
    "        precision.append(precision_score(y_test, predicted))\n",
    "        recall.append(recall_score(y_test, predicted))\n",
    "\n",
    "    print(str(i) + ': acc(' + str(np.mean(accuracy)) \n",
    "          + '), prec(' + str(np.mean(precision))\n",
    "          + '), rec(' + str(np.mean(recall)) + ')'\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900: acc(0.79312911726), prec(0.788461538462), rec(0.933261855926)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=900, strip_accents='unicode', stop_words=stopwords)\n",
    "data = vectorizer.fit_transform(corpus.content)\n",
    "\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "\n",
    "    model = oll.oll(\"CW\", C=1)\n",
    "    \n",
    "    X_train, X_test = data[train_index], data[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    predicted = model.predict(X_test)\n",
    "\n",
    "    accuracy.append(accuracy_score(y_test, predicted))\n",
    "    precision.append(precision_score(y_test, predicted))\n",
    "    recall.append(recall_score(y_test, predicted))\n",
    "\n",
    "print(str(len(vectorizer.get_feature_names())) + ': acc(' + str(np.mean(accuracy)) \n",
    "          + '), prec(' + str(np.mean(precision))\n",
    "          + '), rec(' + str(np.mean(recall)) + ')'\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "pd.DataFrame(feature_names).to_csv('feature_names_cw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
