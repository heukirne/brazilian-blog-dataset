{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "corpus = pd.read_csv('corpus.csv.gz', compression='gzip')\n",
    "stopwords = stopwords.words(\"portuguese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# fix labels to binary\n",
    "lb = preprocessing.LabelBinarizer(neg_label=1, pos_label=2)\n",
    "target = lb.fit_transform(corpus['qual_a_melhor_classificao_para_esse_texto'].values)\n",
    "c, r = target.shape\n",
    "target = target.reshape(c,)\n",
    "\n",
    "model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500: f1(0.8), acc(0.7), precision(0.69), recall(0.94)\n",
      "600: f1(0.81), acc(0.71), precision(0.7), recall(0.94)\n",
      "700: f1(0.8), acc(0.71), precision(0.7), recall(0.94)\n",
      "800: f1(0.8), acc(0.71), precision(0.7), recall(0.94)\n",
      "900: f1(0.81), acc(0.72), precision(0.71), recall(0.94)\n",
      "1000: f1(0.81), acc(0.72), precision(0.71), recall(0.93)\n",
      "1100: f1(0.81), acc(0.72), precision(0.71), recall(0.93)\n",
      "1200: f1(0.81), acc(0.72), precision(0.72), recall(0.93)\n",
      "1300: f1(0.81), acc(0.72), precision(0.71), recall(0.94)\n",
      "1400: f1(0.81), acc(0.72), precision(0.71), recall(0.94)\n",
      "1500: f1(0.81), acc(0.72), precision(0.71), recall(0.94)\n",
      "1600: f1(0.82), acc(0.73), precision(0.71), recall(0.95)\n",
      "1700: f1(0.82), acc(0.73), precision(0.71), recall(0.95)\n",
      "1800: f1(0.81), acc(0.72), precision(0.71), recall(0.95)\n",
      "1900: f1(0.81), acc(0.72), precision(0.71), recall(0.95)\n",
      "2000: f1(0.81), acc(0.72), precision(0.7), recall(0.95)\n",
      "2100: f1(0.81), acc(0.72), precision(0.7), recall(0.96)\n",
      "2200: f1(0.81), acc(0.72), precision(0.71), recall(0.96)\n",
      "2300: f1(0.81), acc(0.72), precision(0.7), recall(0.96)\n",
      "2400: f1(0.81), acc(0.72), precision(0.7), recall(0.96)\n",
      "2500: f1(0.81), acc(0.72), precision(0.7), recall(0.96)\n",
      "2600: f1(0.81), acc(0.72), precision(0.7), recall(0.96)\n",
      "2700: f1(0.81), acc(0.71), precision(0.7), recall(0.96)\n",
      "2800: f1(0.81), acc(0.72), precision(0.7), recall(0.97)\n",
      "2900: f1(0.81), acc(0.71), precision(0.7), recall(0.97)\n",
      "3000: f1(0.81), acc(0.71), precision(0.7), recall(0.97)\n",
      "3100: f1(0.81), acc(0.71), precision(0.7), recall(0.97)\n",
      "3200: f1(0.81), acc(0.71), precision(0.69), recall(0.97)\n",
      "3300: f1(0.81), acc(0.71), precision(0.69), recall(0.97)\n",
      "3400: f1(0.8), acc(0.7), precision(0.69), recall(0.97)\n",
      "3500: f1(0.8), acc(0.7), precision(0.69), recall(0.97)\n",
      "3600: f1(0.8), acc(0.7), precision(0.69), recall(0.97)\n",
      "3700: f1(0.8), acc(0.7), precision(0.68), recall(0.97)\n",
      "3800: f1(0.8), acc(0.7), precision(0.68), recall(0.98)\n",
      "3900: f1(0.8), acc(0.7), precision(0.69), recall(0.98)\n",
      "4000: f1(0.8), acc(0.7), precision(0.68), recall(0.98)\n",
      "4100: f1(0.8), acc(0.7), precision(0.68), recall(0.98)\n",
      "4200: f1(0.8), acc(0.7), precision(0.68), recall(0.98)\n",
      "4300: f1(0.8), acc(0.7), precision(0.68), recall(0.98)\n",
      "4400: f1(0.8), acc(0.7), precision(0.68), recall(0.98)\n",
      "4500: f1(0.8), acc(0.69), precision(0.68), recall(0.98)\n",
      "4600: f1(0.8), acc(0.7), precision(0.68), recall(0.98)\n",
      "4700: f1(0.8), acc(0.7), precision(0.68), recall(0.98)\n",
      "4800: f1(0.8), acc(0.69), precision(0.68), recall(0.98)\n",
      "4900: f1(0.8), acc(0.69), precision(0.68), recall(0.98)\n"
     ]
    }
   ],
   "source": [
    "for i in range(500,5000,100):\n",
    "    data = TfidfVectorizer(max_features=i, strip_accents='unicode', stop_words=stopwords).fit_transform(corpus.content)\n",
    "\n",
    "    f1 = cross_val_score(model, data.toarray(), target, cv=10, scoring='f1').mean()\n",
    "    acc = cross_val_score(model, data.toarray(), target, cv=10, scoring='accuracy').mean()\n",
    "    recall = cross_val_score(model, data.toarray(), target, cv=10, scoring='recall').mean()\n",
    "    precision = cross_val_score(model, data.toarray(), target, cv=10, scoring='precision').mean()\n",
    "    \n",
    "    print(str(i) + ': ' + 'f1(' + str(round(f1,2)) \n",
    "          + '), acc(' + str(round(acc,2)) \n",
    "          + '), precision(' + str(round(precision,2)) \n",
    "          + '), recall(' + str(round(recall,2)) + ')') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600: f1(0.82), acc(0.73), recall(0.95)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1600, ngram_range=(1,1), \n",
    "                             strip_accents='unicode', stop_words=stopwords)\n",
    "data = vectorizer.fit_transform(corpus.content)\n",
    "\n",
    "f1 = cross_val_score(model, data.toarray(), target, cv=10, scoring='f1').mean()\n",
    "acc = cross_val_score(model, data.toarray(), target, cv=10, scoring='accuracy').mean()\n",
    "recall = cross_val_score(model, data.toarray(), target, cv=10, scoring='recall').mean()\n",
    "\n",
    "print(str(1600) + ': ' + 'f1(' + str(round(f1,2)) \n",
    "      + '), acc(' + str(round(acc,2)) \n",
    "          + '), recall(' + str(round(recall,2)) + ')') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outro -8.42840062262 cu\n",
      "outro -8.42840062262 fila\n",
      "outro -8.34170450478 sentada\n",
      "outro -8.31877614505 delicia\n",
      "outro -8.30412835281 arroz\n",
      "outro -8.28116258082 estavamos\n",
      "outro -8.27818574845 barra\n",
      "outro -8.26333103888 pau\n",
      "outro -8.25738320847 rsrs\n",
      "outro -8.23837942924 passe\n",
      "outro -8.23520115028 paris\n",
      "outro -8.23197234622 experiencias\n",
      "outro -8.22789515148 mandou\n",
      "outro -8.19827767411 procurando\n",
      "outro -8.194199319 saiba\n",
      "\n",
      "diario -4.7558889968 nao\n",
      "diario -5.38686687879 voce\n",
      "diario -5.60623869012 deus\n",
      "diario -5.77658655193 ser\n",
      "diario -5.87346286987 pra\n",
      "diario -5.91141740959 vida\n",
      "diario -5.93281533584 sao\n",
      "diario -5.98216293634 ja\n",
      "diario -5.99317315418 sobre\n",
      "diario -6.02986949287 tambem\n",
      "diario -6.05648081852 bem\n",
      "diario -6.06118712102 tudo\n",
      "diario -6.06154549924 so\n",
      "diario -6.10294784233 dia\n",
      "diario -6.10774054733 aqui\n"
     ]
    }
   ],
   "source": [
    "model.fit(data.toarray(),target)\n",
    "n = 15 \n",
    "\n",
    "class_labels = ['outro','diario']\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "topn_class1 = sorted(zip(model.coef_[0], feature_names))[:n]\n",
    "topn_class2 = sorted(zip(model.coef_[0], feature_names))[-n:]\n",
    "\n",
    "for coef, feat in topn_class1:\n",
    "    print (class_labels[0], coef, feat)\n",
    "\n",
    "print()\n",
    "\n",
    "for coef, feat in reversed(topn_class2):\n",
    "    print (class_labels[1], coef, feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800: f1(0.82), acc(0.73), recall(0.94)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1600, ngram_range=(1,1), \n",
    "                             strip_accents='unicode', stop_words=stopwords)\n",
    "data = vectorizer.fit_transform(corpus.content)\n",
    "\n",
    "model.fit(data.toarray(),target)\n",
    "n = 400 \n",
    "\n",
    "class_labels = ['outro','diario']\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "topn_class1 = sorted(zip(model.coef_[0], feature_names))[:n]\n",
    "topn_class2 = sorted(zip(model.coef_[0], feature_names))[-n:]\n",
    "\n",
    "vocabulary = []\n",
    "\n",
    "for coef, feat in topn_class1:\n",
    "    if feat not in vocabulary: \n",
    "        vocabulary.append(feat)\n",
    "for coef, feat in reversed(topn_class2):\n",
    "    if feat not in vocabulary: \n",
    "        vocabulary.append(feat)\n",
    "    \n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,1), strip_accents='unicode', \n",
    "                             stop_words=stopwords, vocabulary=vocabulary)\n",
    "data = vectorizer.fit_transform(corpus.content)\n",
    "\n",
    "f1 = cross_val_score(model, data.toarray(), target, cv=10, scoring='f1').mean()\n",
    "acc = cross_val_score(model, data.toarray(), target, cv=10, scoring='accuracy').mean()\n",
    "recall = cross_val_score(model, data.toarray(), target, cv=10, scoring='recall').mean()\n",
    "\n",
    "print(str(len(vectorizer.get_feature_names())) + ': ' + 'f1(' + str(round(f1,2)) \n",
    "      + '), acc(' + str(round(acc,2)) \n",
    "          + '), recall(' + str(round(recall,2)) + ')') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outro -8.08988280427 cu\n",
      "outro -8.08988280427 fila\n",
      "outro -7.98351493146 sentada\n",
      "outro -7.92703328594 arroz\n",
      "outro -7.89059145104 barra\n",
      "outro -7.88473954565 pau\n",
      "outro -7.87436582665 rsrs\n",
      "outro -7.86612067399 experiencias\n",
      "outro -7.86033072728 mandou\n",
      "outro -7.85431620812 delicia\n",
      "outro -7.83669833205 paris\n",
      "outro -7.83376406304 passe\n",
      "outro -7.81637439594 estavamos\n",
      "outro -7.80231057735 procurando\n",
      "outro -7.78411372006 saiba\n",
      "\n",
      "diario -4.13416892021 nao\n",
      "diario -4.7803952574 voce\n",
      "diario -5.0616782835 deus\n",
      "diario -5.15135249475 ser\n",
      "diario -5.24638918025 pra\n",
      "diario -5.30946818547 sao\n",
      "diario -5.33918782585 vida\n",
      "diario -5.36797221208 ja\n",
      "diario -5.396421643 sobre\n",
      "diario -5.41043837627 tambem\n",
      "diario -5.44594277303 so\n",
      "diario -5.45216460513 bem\n",
      "diario -5.47079139909 tudo\n",
      "diario -5.49493630236 aqui\n",
      "diario -5.50209285846 dia\n"
     ]
    }
   ],
   "source": [
    "model.fit(data.toarray(),target)\n",
    "n = 15 \n",
    "\n",
    "class_labels = ['outro','diario']\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "topn_class1 = sorted(zip(model.coef_[0], feature_names))[:n]\n",
    "topn_class2 = sorted(zip(model.coef_[0], feature_names))[-n:]\n",
    "\n",
    "for coef, feat in topn_class1:\n",
    "    print (class_labels[0], coef, feat)\n",
    "\n",
    "print()\n",
    "\n",
    "for coef, feat in reversed(topn_class2):\n",
    "    print (class_labels[1], coef, feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns=vectorizer.get_feature_names()\n",
    "pdCSV = pd.DataFrame(data.toarray(),columns=columns)\n",
    "pdCSV['class'] = corpus['qual_a_melhor_classificao_para_esse_texto'].values\n",
    "#pdCSV.to_csv('tfidfFeatures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
