{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "corpus = pd.read_csv('corpus.csv.gz', compression='gzip')\n",
    "stopwords = stopwords.words(\"portuguese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(534, 23)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#corpus = corpus[corpus['_golden'] == False]\n",
    "corpus = corpus[corpus['qual_a_melhor_classificao_para_esse_texto:confidence'] == 1]\n",
    "corpus = corpus.reset_index()\n",
    "corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['diario' 'outro']\n",
      "0    1\n",
      "1   -1\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# fix labels to binary\n",
    "def classFit(x):\n",
    "    if x['qual_a_melhor_classificao_para_esse_texto'] == \"diario\":\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "corpus['class'] = corpus.apply(classFit,axis=1)\n",
    "target = corpus['class'].values\n",
    "\n",
    "print(corpus['qual_a_melhor_classificao_para_esse_texto'].values[:2])\n",
    "print(corpus['class'][:2])\n",
    "\n",
    "model = MultinomialNB(alpha=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import nltk.stem\n",
    "portuguese_stemmer = nltk.stem.RSLPStemmer()\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(TfidfVectorizer,self).build_analyzer()\n",
    "        return lambda doc: (portuguese_stemmer.stem(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500: f1(0.8385), acc(0.7641), precision(0.7565), recall(0.9422)\n",
      "600: f1(0.835), acc(0.7585), precision(0.7522), recall(0.9393)\n",
      "700: f1(0.837), acc(0.764), precision(0.7593), recall(0.9334)\n",
      "800: f1(0.8362), acc(0.7659), precision(0.7664), recall(0.9218)\n",
      "900: f1(0.8499), acc(0.7882), precision(0.7882), recall(0.9246)\n",
      "1000: f1(0.8494), acc(0.7884), precision(0.7891), recall(0.9218)\n",
      "1100: f1(0.8575), acc(0.7996), precision(0.7971), recall(0.9303)\n",
      "1200: f1(0.8544), acc(0.7958), precision(0.795), recall(0.9246)\n",
      "1300: f1(0.855), acc(0.7977), precision(0.8003), recall(0.9189)\n",
      "1400: f1(0.8506), acc(0.7904), precision(0.7926), recall(0.919)\n",
      "1500: f1(0.854), acc(0.7941), precision(0.7946), recall(0.9247)\n",
      "1600: f1(0.8479), acc(0.7849), precision(0.7857), recall(0.9218)\n",
      "1700: f1(0.8457), acc(0.7831), precision(0.7882), recall(0.9134)\n",
      "1800: f1(0.8447), acc(0.7813), precision(0.7862), recall(0.9135)\n",
      "1900: f1(0.8494), acc(0.787), precision(0.788), recall(0.9222)\n",
      "2000: f1(0.8426), acc(0.7794), precision(0.7876), recall(0.9076)\n",
      "2100: f1(0.8378), acc(0.7719), precision(0.7785), recall(0.9076)\n",
      "2200: f1(0.8385), acc(0.7718), precision(0.7777), recall(0.9105)\n",
      "2300: f1(0.8377), acc(0.7717), precision(0.7786), recall(0.9075)\n",
      "2400: f1(0.8343), acc(0.7678), precision(0.777), recall(0.9015)\n",
      "2500: f1(0.8365), acc(0.7716), precision(0.7806), recall(0.9016)\n",
      "2600: f1(0.8358), acc(0.7696), precision(0.7771), recall(0.9045)\n",
      "2700: f1(0.8353), acc(0.7697), precision(0.7784), recall(0.9016)\n",
      "2800: f1(0.8421), acc(0.7791), precision(0.7841), recall(0.9103)\n",
      "2900: f1(0.8394), acc(0.7754), precision(0.7814), recall(0.9074)\n",
      "3000: f1(0.8368), acc(0.7717), precision(0.7793), recall(0.9045)\n",
      "3100: f1(0.8405), acc(0.7774), precision(0.7836), recall(0.9075)\n",
      "3200: f1(0.84), acc(0.7756), precision(0.7805), recall(0.9103)\n",
      "3300: f1(0.8412), acc(0.7773), precision(0.783), recall(0.9103)\n",
      "3400: f1(0.8386), acc(0.7735), precision(0.7805), recall(0.9075)\n",
      "3500: f1(0.8328), acc(0.766), precision(0.7771), recall(0.8988)\n",
      "3600: f1(0.8262), acc(0.7566), precision(0.772), recall(0.8901)\n",
      "3700: f1(0.8277), acc(0.7585), precision(0.773), recall(0.8929)\n",
      "3800: f1(0.831), acc(0.7641), precision(0.7785), recall(0.8929)\n",
      "3900: f1(0.8295), acc(0.7622), precision(0.7782), recall(0.8901)\n",
      "4000: f1(0.8294), acc(0.7621), precision(0.7779), recall(0.8901)\n",
      "4100: f1(0.829), acc(0.7621), precision(0.7794), recall(0.8871)\n",
      "4200: f1(0.8309), acc(0.7641), precision(0.7779), recall(0.8929)\n",
      "4300: f1(0.8294), acc(0.7622), precision(0.7772), recall(0.8901)\n",
      "4400: f1(0.8328), acc(0.7679), precision(0.7835), recall(0.8901)\n",
      "4500: f1(0.8309), acc(0.7641), precision(0.7779), recall(0.8929)\n",
      "4600: f1(0.8294), acc(0.7622), precision(0.7773), recall(0.8901)\n",
      "4700: f1(0.8291), acc(0.7622), precision(0.779), recall(0.8872)\n",
      "4800: f1(0.8346), acc(0.7697), precision(0.785), recall(0.893)\n",
      "4900: f1(0.8323), acc(0.766), precision(0.7808), recall(0.893)\n"
     ]
    }
   ],
   "source": [
    "for i in range(500,5000,100):\n",
    "    data = TfidfVectorizer(max_features=i, strip_accents='unicode', stop_words=stopwords).fit_transform(corpus.content)\n",
    "\n",
    "    f1 = cross_val_score(model, data.toarray(), target, cv=10, scoring='f1').mean()\n",
    "    acc = cross_val_score(model, data.toarray(), target, cv=10, scoring='accuracy').mean()\n",
    "    recall = cross_val_score(model, data.toarray(), target, cv=10, scoring='recall').mean()\n",
    "    precision = cross_val_score(model, data.toarray(), target, cv=10, scoring='precision').mean()\n",
    "    \n",
    "    print(str(i) + ': ' + 'f1(' + str(round(f1,4)) \n",
    "          + '), acc(' + str(round(acc,4)) \n",
    "          + '), precision(' + str(round(precision,4)) \n",
    "          + '), recall(' + str(round(recall,4)) + ')') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300: precision(0.8), acc(0.798), recall(0.919)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1300, ngram_range=(1,1), \n",
    "                             strip_accents='unicode', stop_words=stopwords)\n",
    "data = vectorizer.fit_transform(corpus.content)\n",
    "\n",
    "precision = cross_val_score(model, data.toarray(), target, cv=10, scoring='precision').mean()\n",
    "acc = cross_val_score(model, data.toarray(), target, cv=10, scoring='accuracy').mean()\n",
    "recall = cross_val_score(model, data.toarray(), target, cv=10, scoring='recall').mean()\n",
    "\n",
    "print(str(len(vectorizer.get_feature_names())) + ': ' + 'precision(' + str(round(precision,3)) \n",
    "      + '), acc(' + str(round(acc,3)) \n",
    "          + '), recall(' + str(round(recall,3)) + ')') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "pd.DataFrame(feature_names).to_csv('feature_names.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outro -14.7878978495 arthur\n",
      "outro -14.7878978495 atitudes\n",
      "outro -14.7878978495 comunidade\n",
      "outro -14.7878978495 fulo\n",
      "outro -14.7878978495 lohraine\n",
      "outro -14.7878978495 now\n",
      "outro -14.7878978495 plus\n",
      "outro -14.7878978495 selena\n",
      "outro -10.547722584 evangelho\n",
      "outro -10.4039007241 mundial\n",
      "outro -10.0293200155 advogado\n",
      "outro -9.98360378444 mr\n",
      "outro -9.77741076852 fas\n",
      "outro -9.75317446918 salvacao\n",
      "outro -9.71612308875 en\n",
      "\n",
      "diario -4.21819974347 nao\n",
      "diario -4.90847526335 pra\n",
      "diario -4.93069608442 voce\n",
      "diario -5.33995847914 ja\n",
      "diario -5.34153141504 dia\n",
      "diario -5.36732774429 tudo\n",
      "diario -5.38342771941 ser\n",
      "diario -5.40606660952 so\n",
      "diario -5.46632612062 ate\n",
      "diario -5.49844306499 bem\n",
      "diario -5.51739591374 vida\n",
      "diario -5.5354423855 aqui\n",
      "diario -5.58016078776 sempre\n",
      "diario -5.61213366781 sao\n",
      "diario -5.62191566613 vou\n"
     ]
    }
   ],
   "source": [
    "model.fit(data.toarray(),target)\n",
    "n = 15 \n",
    "\n",
    "class_labels = ['outro','diario']\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "topn_class1 = sorted(zip(model.coef_[0], feature_names))[:n]\n",
    "topn_class2 = sorted(zip(model.coef_[0], feature_names))[-n:]\n",
    "\n",
    "for coef, feat in topn_class1:\n",
    "    print (class_labels[0], coef, feat)\n",
    "\n",
    "print()\n",
    "\n",
    "for coef, feat in reversed(topn_class2):\n",
    "    print (class_labels[1], coef, feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800: precision(0.8), acc(0.79), recall(0.91)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1300, ngram_range=(1,1), \n",
    "                             strip_accents='unicode', stop_words=stopwords)\n",
    "data = vectorizer.fit_transform(corpus.content)\n",
    "\n",
    "model.fit(data.toarray(),target)\n",
    "n = 400 \n",
    "\n",
    "class_labels = ['outro','diario']\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "topn_class1 = sorted(zip(model.coef_[0], feature_names))[:n]\n",
    "topn_class2 = sorted(zip(model.coef_[0], feature_names))[-n:]\n",
    "\n",
    "vocabulary = []\n",
    "\n",
    "for coef, feat in topn_class1:\n",
    "    if feat not in vocabulary: \n",
    "        vocabulary.append(feat)\n",
    "for coef, feat in reversed(topn_class2):\n",
    "    if feat not in vocabulary: \n",
    "        vocabulary.append(feat)\n",
    "    \n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,1), strip_accents='unicode', \n",
    "                             stop_words=stopwords, vocabulary=vocabulary)\n",
    "data = vectorizer.fit_transform(corpus.content)\n",
    "\n",
    "precision = cross_val_score(model, data.toarray(), target, cv=10, scoring='precision').mean()\n",
    "acc = cross_val_score(model, data.toarray(), target, cv=10, scoring='accuracy').mean()\n",
    "recall = cross_val_score(model, data.toarray(), target, cv=10, scoring='recall').mean()\n",
    "\n",
    "print(str(len(vectorizer.get_feature_names())) + ': ' + 'precision(' + str(round(precision,2)) \n",
    "      + '), acc(' + str(round(acc,2)) \n",
    "          + '), recall(' + str(round(recall,2)) + ')') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outro -14.6627577022 arthur\n",
      "outro -14.6627577022 atitudes\n",
      "outro -14.6627577022 comunidade\n",
      "outro -14.6627577022 fulo\n",
      "outro -14.6627577022 lohraine\n",
      "outro -14.6627577022 now\n",
      "outro -14.6627577022 plus\n",
      "outro -14.6627577022 selena\n",
      "outro -10.0362471343 mundial\n",
      "outro -10.0129388666 evangelho\n",
      "outro -9.75480798621 advogado\n",
      "outro -9.73384698486 mr\n",
      "outro -9.50777508087 salvacao\n",
      "outro -9.43977702604 en\n",
      "outro -9.3167891835 entrevista\n",
      "\n",
      "diario -3.90016723557 nao\n",
      "diario -4.59419454387 pra\n",
      "diario -4.6271610713 voce\n",
      "diario -4.99835696309 ja\n",
      "diario -5.02619837016 dia\n",
      "diario -5.04501682262 tudo\n",
      "diario -5.07540497046 ser\n",
      "diario -5.08322100641 so\n",
      "diario -5.13554177006 ate\n",
      "diario -5.1701492655 bem\n",
      "diario -5.2060493309 aqui\n",
      "diario -5.21538525439 vida\n",
      "diario -5.25538076449 sempre\n",
      "diario -5.2751581612 sao\n",
      "diario -5.3005574071 vou\n"
     ]
    }
   ],
   "source": [
    "model.fit(data.toarray(),target)\n",
    "n = 15 \n",
    "\n",
    "class_labels = ['outro','diario']\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "topn_class1 = sorted(zip(model.coef_[0], feature_names))[:n]\n",
    "topn_class2 = sorted(zip(model.coef_[0], feature_names))[-n:]\n",
    "\n",
    "for coef, feat in topn_class1:\n",
    "    print (class_labels[0], coef, feat)\n",
    "\n",
    "print()\n",
    "\n",
    "for coef, feat in reversed(topn_class2):\n",
    "    print (class_labels[1], coef, feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(feature_names).to_csv('feature_names.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
